{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9faa064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import datetime, os\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af03285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "93ea6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "\n",
    "DATA_PATH = '/Users/alex791/Library/CloudStorage/OneDrive-PNNL/Documents/Projects/ML_Earth_Projects/Reservoir_Project/Data'\n",
    "HP_TUNING_PATH = '/Users/alex791/Library/CloudStorage/OneDrive-PNNL/Documents/Projects/ML_Earth_Projects/Reservoir_Project/Hyperparameter_Tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "500f705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_inflow_train = pd.read_excel(f'{DATA_PATH}/Custom/basin_inflow_train.xlsx', index_col=0)\n",
    "basin_inflow_validation = pd.read_excel(f'{DATA_PATH}/Custom/basin_inflow_validation.xlsx', index_col=0)\n",
    "basin_inflow_test = pd.read_excel(f'{DATA_PATH}/Custom/basin_inflow_test.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "60024804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFLOW</th>\n",
       "      <th>ADR_PRECIP_ACC</th>\n",
       "      <th>ADR_PRECIP_INCR</th>\n",
       "      <th>ADR_TEMP_AVG</th>\n",
       "      <th>ADR_TEMP_MAX</th>\n",
       "      <th>ADR_TEMP_MIN</th>\n",
       "      <th>HYS_PRECIP_ACC</th>\n",
       "      <th>HYS_PRECIP_INCR</th>\n",
       "      <th>HYS_SNOW_DEPTH</th>\n",
       "      <th>HYS_SNOW_WATER_CONTENT</th>\n",
       "      <th>...</th>\n",
       "      <th>FRN_SNOW_DEPTH</th>\n",
       "      <th>FRN_SNOW_WATER_CONTENT</th>\n",
       "      <th>FRN_TEMP_AVG</th>\n",
       "      <th>FRN_TEMP_MAX</th>\n",
       "      <th>FRN_TEMP_MIN</th>\n",
       "      <th>PFH_PRECIP_ACC</th>\n",
       "      <th>PFH_PRECIP_INCR</th>\n",
       "      <th>PFH_TEMP_AVG</th>\n",
       "      <th>PFH_TEMP_MAX</th>\n",
       "      <th>PFH_TEMP_MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044963</td>\n",
       "      <td>-0.289112</td>\n",
       "      <td>0.340301</td>\n",
       "      <td>0.054044</td>\n",
       "      <td>-0.375165</td>\n",
       "      <td>0.305438</td>\n",
       "      <td>-0.011090</td>\n",
       "      <td>0.388324</td>\n",
       "      <td>-0.123764</td>\n",
       "      <td>0.061586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108819</td>\n",
       "      <td>0.183304</td>\n",
       "      <td>-0.491096</td>\n",
       "      <td>-0.610589</td>\n",
       "      <td>-0.458829</td>\n",
       "      <td>-0.078244</td>\n",
       "      <td>0.224818</td>\n",
       "      <td>-0.039676</td>\n",
       "      <td>-0.564907</td>\n",
       "      <td>0.045612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045396</td>\n",
       "      <td>-0.283597</td>\n",
       "      <td>0.376414</td>\n",
       "      <td>-0.093752</td>\n",
       "      <td>-0.373458</td>\n",
       "      <td>0.056615</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>0.419682</td>\n",
       "      <td>-0.106719</td>\n",
       "      <td>0.069362</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113669</td>\n",
       "      <td>0.185770</td>\n",
       "      <td>-0.363760</td>\n",
       "      <td>-0.448188</td>\n",
       "      <td>-0.336938</td>\n",
       "      <td>-0.073231</td>\n",
       "      <td>0.299318</td>\n",
       "      <td>-0.030774</td>\n",
       "      <td>-0.682164</td>\n",
       "      <td>0.086839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.039165</td>\n",
       "      <td>-0.281148</td>\n",
       "      <td>0.243520</td>\n",
       "      <td>-0.113826</td>\n",
       "      <td>-0.227147</td>\n",
       "      <td>-0.029060</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>0.442274</td>\n",
       "      <td>-0.093225</td>\n",
       "      <td>0.079873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118205</td>\n",
       "      <td>0.188094</td>\n",
       "      <td>-0.202812</td>\n",
       "      <td>-0.252427</td>\n",
       "      <td>-0.180427</td>\n",
       "      <td>-0.068255</td>\n",
       "      <td>0.297508</td>\n",
       "      <td>-0.093725</td>\n",
       "      <td>-0.530415</td>\n",
       "      <td>0.041245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022834</td>\n",
       "      <td>-0.290972</td>\n",
       "      <td>-0.313413</td>\n",
       "      <td>-0.146230</td>\n",
       "      <td>-0.155065</td>\n",
       "      <td>-0.157082</td>\n",
       "      <td>-0.009333</td>\n",
       "      <td>-0.549211</td>\n",
       "      <td>-0.092705</td>\n",
       "      <td>0.087465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116945</td>\n",
       "      <td>0.188011</td>\n",
       "      <td>-0.136433</td>\n",
       "      <td>-0.141606</td>\n",
       "      <td>-0.138177</td>\n",
       "      <td>-0.078026</td>\n",
       "      <td>-0.428531</td>\n",
       "      <td>-0.105323</td>\n",
       "      <td>-0.350378</td>\n",
       "      <td>-0.056045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.014312</td>\n",
       "      <td>-0.300133</td>\n",
       "      <td>-0.389419</td>\n",
       "      <td>-0.063319</td>\n",
       "      <td>-0.042481</td>\n",
       "      <td>-0.134920</td>\n",
       "      <td>-0.015781</td>\n",
       "      <td>-0.591777</td>\n",
       "      <td>-0.109237</td>\n",
       "      <td>0.075137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.127933</td>\n",
       "      <td>0.188631</td>\n",
       "      <td>-0.087231</td>\n",
       "      <td>-0.053518</td>\n",
       "      <td>-0.108681</td>\n",
       "      <td>-0.086058</td>\n",
       "      <td>-0.465569</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>-0.102076</td>\n",
       "      <td>-0.086963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INFLOW  ADR_PRECIP_ACC  ADR_PRECIP_INCR  ADR_TEMP_AVG  ADR_TEMP_MAX  \\\n",
       "0  0.044963       -0.289112         0.340301      0.054044     -0.375165   \n",
       "1  0.045396       -0.283597         0.376414     -0.093752     -0.373458   \n",
       "2  0.039165       -0.281148         0.243520     -0.113826     -0.227147   \n",
       "3  0.022834       -0.290972        -0.313413     -0.146230     -0.155065   \n",
       "4 -0.014312       -0.300133        -0.389419     -0.063319     -0.042481   \n",
       "\n",
       "   ADR_TEMP_MIN  HYS_PRECIP_ACC  HYS_PRECIP_INCR  HYS_SNOW_DEPTH  \\\n",
       "0      0.305438       -0.011090         0.388324       -0.123764   \n",
       "1      0.056615       -0.006376         0.419682       -0.106719   \n",
       "2     -0.029060       -0.001178         0.442274       -0.093225   \n",
       "3     -0.157082       -0.009333        -0.549211       -0.092705   \n",
       "4     -0.134920       -0.015781        -0.591777       -0.109237   \n",
       "\n",
       "   HYS_SNOW_WATER_CONTENT  ...  FRN_SNOW_DEPTH  FRN_SNOW_WATER_CONTENT  \\\n",
       "0                0.061586  ...        0.108819                0.183304   \n",
       "1                0.069362  ...        0.113669                0.185770   \n",
       "2                0.079873  ...        0.118205                0.188094   \n",
       "3                0.087465  ...        0.116945                0.188011   \n",
       "4                0.075137  ...        0.127933                0.188631   \n",
       "\n",
       "   FRN_TEMP_AVG  FRN_TEMP_MAX  FRN_TEMP_MIN  PFH_PRECIP_ACC  PFH_PRECIP_INCR  \\\n",
       "0     -0.491096     -0.610589     -0.458829       -0.078244         0.224818   \n",
       "1     -0.363760     -0.448188     -0.336938       -0.073231         0.299318   \n",
       "2     -0.202812     -0.252427     -0.180427       -0.068255         0.297508   \n",
       "3     -0.136433     -0.141606     -0.138177       -0.078026        -0.428531   \n",
       "4     -0.087231     -0.053518     -0.108681       -0.086058        -0.465569   \n",
       "\n",
       "   PFH_TEMP_AVG  PFH_TEMP_MAX  PFH_TEMP_MIN  \n",
       "0     -0.039676     -0.564907      0.045612  \n",
       "1     -0.030774     -0.682164      0.086839  \n",
       "2     -0.093725     -0.530415      0.041245  \n",
       "3     -0.105323     -0.350378     -0.056045  \n",
       "4      0.009074     -0.102076     -0.086963  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_inflow_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d978f",
   "metadata": {},
   "source": [
    "### Data windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d373e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow utility class for producing data windows from time series data\n",
    "\n",
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "    \n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "    \n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "aeb825cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.WindowGenerator at 0x2a5273c50>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Window\n",
    "- Given 60 days of history predict 30 days into the future. Why? A season is about 90 days in a CA WY\n",
    "- Window size: 90\n",
    "\"\"\"\n",
    "\n",
    "window = WindowGenerator(input_width=60, label_width=1, shift=30,\n",
    "                     train_df=basin_inflow_train, val_df=basin_inflow_validation, \n",
    "                     test_df=basin_inflow_test, label_columns=['INFLOW'])\n",
    "\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "379f5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a window of inputs and labels\n",
    "\n",
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # set shapes after slicing\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3e37dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset of sliding windows over a time series dataframe\n",
    "\n",
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=32,)\n",
    "\n",
    "  # (input_window, label_window) pairs \n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5f27daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "70d6de41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 60, 36), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each element is an (inputs, label) pair\n",
    "window.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dd26e712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 60, 36)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# example batch\n",
    "for inputs, labels in window.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd065a",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "51bec92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "test_performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37286bc8",
   "metadata": {},
   "source": [
    "#### Create baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "29a12380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow baseline utility class for data windowing\n",
    "\n",
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs\n",
    "    result = inputs[:, :, self.label_index]\n",
    "    return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c392c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 488us/step - loss: 0.1517 - mean_absolute_error: 0.1517\n"
     ]
    }
   ],
   "source": [
    "baseline = Baseline(label_index=window.column_indices['INFLOW'])\n",
    "\n",
    "baseline.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance['Baseline'] = baseline.evaluate(window.val)\n",
    "test_performance['Baseline'] = baseline.evaluate(window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742bf48",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fa2344c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping, tensorboard_callback])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372162e",
   "metadata": {},
   "source": [
    "LSTM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c3d2634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inputs shape (batch, time, features): (32, 60, 36) - 32 batch size, 60 time steps, 36 features\n",
    "\"\"\"\n",
    "\n",
    "lstm_v1 = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 36]),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d02e6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0628 - val_loss: 0.1552\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0452 - val_loss: 0.1385\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0414 - val_loss: 0.1315\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0399 - val_loss: 0.1284\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0374 - val_loss: 0.1295\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0362 - val_loss: 0.1387\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v1 = compile_and_fit(lstm_v1, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf66920",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "400cf07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1387\n",
      "LSTM 1 Validation performance:  0.13874830305576324\n",
      "LSTM 1 Test performance:  0.14985796809196472\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM1'] = lstm_v1.evaluate(window.val)\n",
    "test_performance['LSTM1'] = lstm_v1.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 1 Validation performance: ', val_performance['LSTM1'])\n",
    "print('LSTM 1 Test performance: ', test_performance['LSTM1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a035828",
   "metadata": {},
   "source": [
    "LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6ce4faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v2 = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 36]),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e28ec0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 2s 17ms/step - loss: 0.0430 - val_loss: 0.1555\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0321 - val_loss: 0.1474\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0297 - val_loss: 0.1514\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0257 - val_loss: 0.1452\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0229 - val_loss: 0.1514\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0203 - val_loss: 0.1527\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v2 = compile_and_fit(lstm_v2, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec16a472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45646), started 0:23:25 ago. (Use '!kill 45646' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c40f9f7f74bb1ff\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c40f9f7f74bb1ff\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1c735a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1527\n",
      "LSTM 2 Validation performance:  0.15269407629966736\n",
      "LSTM 2 Test performance:  0.09494537860155106\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM2'] = lstm_v2.evaluate(window.val)\n",
    "test_performance['LSTM2'] = lstm_v2.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 2 Validation performance: ', val_performance['LSTM2'])\n",
    "print('LSTM 2 Test performance: ', test_performance['LSTM2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a115cd1",
   "metadata": {},
   "source": [
    "LSTM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f2035563",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizedLSTM = partial(tf.keras.layers.LSTM,\n",
    "                           dropout=0.01,\n",
    "                           recurrent_dropout=0.01,\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "704200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v3 = tf.keras.models.Sequential([\n",
    "    RegularizedLSTM(32, return_sequences=True, input_shape=[None, 36]),\n",
    "    RegularizedLSTM(32),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8a5453af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 4s 34ms/step - loss: 3.0731 - val_loss: 1.5350\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.7713 - val_loss: 0.4343\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.1850 - val_loss: 0.1943\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0637 - val_loss: 0.1485\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0437 - val_loss: 0.1551\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0394 - val_loss: 0.1457\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0378 - val_loss: 0.1461\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0378 - val_loss: 0.1465\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v3 = compile_and_fit(lstm_v3, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc31fe6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45646), started 2:07:43 ago. (Use '!kill 45646' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-219c1018de26f1f2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-219c1018de26f1f2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "be242d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1465\n",
      "LSTM 3 Validation performance:  0.14650316536426544\n",
      "LSTM 3 Test performance:  0.07470374554395676\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM3'] = lstm_v3.evaluate(window.val)\n",
    "test_performance['LSTM3'] = lstm_v3.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 3 Validation performance: ', val_performance['LSTM3'])\n",
    "print('LSTM 3 Test performance: ', test_performance['LSTM3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2f773",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b1cd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  lstm = keras.Sequential()\n",
    "\n",
    "  ### Tuning hyperparameters ### \n",
    "\n",
    "  # Number of lstm layer units\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "\n",
    "  # Dropout rate applied to input values\n",
    "  hp_dropout = hp.Choice(\"dropout\", [0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "  # Recurrent dropout rate applied to hidden cell states between time steps\n",
    "  hp_recurrent_dropout = hp.Choice(\"recurrent_dropout\", [0.2, 0.3, 0.4, 0.5])\n",
    "  \n",
    "  # L2 regularization \n",
    "  hp_l2_reg = hp.Choice(\"l2\", [0.001, 0.01, 0.02, 0.05])\n",
    "\n",
    "  # Optimizer learning rate\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "\n",
    "  ### Layers ### \n",
    "  \n",
    "  lstm.add(tf.keras.layers.LSTM(units=hp_units, dropout=hp_dropout, recurrent_dropout=hp_recurrent_dropout, \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2=hp_l2_reg),\n",
    "                  return_sequences=True, input_shape=[None, 36]))\n",
    "    \n",
    "  lstm.add(tf.keras.layers.LSTM(units=hp_units, dropout=hp_dropout, recurrent_dropout=hp_recurrent_dropout, \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2=hp_l2_reg)))\n",
    "    \n",
    "  lstm.add(keras.layers.Dense(1))    \n",
    "    \n",
    "  ### Compile ### \n",
    "           \n",
    "  lstm.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "               optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=hp_learning_rate),\n",
    "               metrics=['mean_absolute_error'])\n",
    "\n",
    "  return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "27d9e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_mean_absolute_error',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory=HP_TUNING_PATH,\n",
    "                     project_name='reservoir_model_hp_tuning_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b8071be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9a5ce375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 50s]\n",
      "val_mean_absolute_error: 0.11860812455415726\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.11121592670679092\n",
      "Total elapsed time: 00h 14m 04s\n"
     ]
    }
   ],
   "source": [
    "# args for search are those used for model fit\n",
    "tuner.search(window.train, epochs=MAX_EPOCHS, validation_data=window.val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f3dacc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete and below are the optimal values:\n",
      "\n",
      "- Units: 32\n",
      "- Dropout: 0.2\n",
      "- Recurrent dropout: 0.5\n",
      "- L2: 0.01\n",
      "- Learning rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete and below are the optimal values:\n",
    "\n",
    "- Units: {best_hps.get('units')}\n",
    "- Dropout: {best_hps.get('dropout')}\n",
    "- Recurrent dropout: {best_hps.get('recurrent_dropout')}\n",
    "- L2: {best_hps.get('l2')}\n",
    "- Learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7a7f3",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "cbc045a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 4s 34ms/step - loss: 0.7020 - mean_absolute_error: 0.0479 - val_loss: 0.4679 - val_mean_absolute_error: 0.1227\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.2459 - mean_absolute_error: 0.0383 - val_loss: 0.2452 - val_mean_absolute_error: 0.1337\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1085 - mean_absolute_error: 0.0374 - val_loss: 0.1761 - val_mean_absolute_error: 0.1333\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0673 - mean_absolute_error: 0.0368 - val_loss: 0.1562 - val_mean_absolute_error: 0.1351\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0526 - mean_absolute_error: 0.0362 - val_loss: 0.1471 - val_mean_absolute_error: 0.1347\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0455 - mean_absolute_error: 0.0352 - val_loss: 0.1465 - val_mean_absolute_error: 0.1381\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0425 - mean_absolute_error: 0.0353 - val_loss: 0.1496 - val_mean_absolute_error: 0.1434\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0405 - mean_absolute_error: 0.0350 - val_loss: 0.1436 - val_mean_absolute_error: 0.1388\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0405 - mean_absolute_error: 0.0360 - val_loss: 0.1357 - val_mean_absolute_error: 0.1315\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0387 - mean_absolute_error: 0.0348 - val_loss: 0.1420 - val_mean_absolute_error: 0.1384\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# first find the optimal number of training epochs\n",
    "\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=2,\n",
    "                                                mode='min')\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(window.train, epochs=MAX_EPOCHS, validation_data=window.val, callbacks=[early_stopping])\n",
    "\n",
    "val_mae_per_epoch = history.history['val_mean_absolute_error']\n",
    "best_epoch = val_mae_per_epoch.index(min(val_mae_per_epoch)) + 1 # find epoch of lowest validation MAE \n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "75134ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 4s 35ms/step - loss: 0.7018 - mean_absolute_error: 0.0480 - val_loss: 0.4654 - val_mean_absolute_error: 0.1236\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=2,\n",
    "                                                mode='min')\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "history = hypermodel.fit(window.train, epochs=best_epoch, validation_data=window.val, \n",
    "                         callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ee1c25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4654 - mean_absolute_error: 0.1236\n",
      "Hypermodel Validation performance:  [0.4653622806072235, 0.1235504150390625]\n",
      "Hypermodel Test performance:  [0.38941654562950134, 0.04760463908314705]\n"
     ]
    }
   ],
   "source": [
    "val_performance['Hypermodel'] = hypermodel.evaluate(window.val)\n",
    "test_performance['Hypermodel'] = hypermodel.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('Hypermodel Validation performance: ', val_performance['Hypermodel'])\n",
    "print('Hypermodel Test performance: ', test_performance['Hypermodel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cfc4b8",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "62e51a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse normalization\n",
    "\n",
    "def inverse_scaling(data):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    fitted_scaler = scaler.fit(data)\n",
    "    inversed_data = fitted_scaler.inverse_transform(data)\n",
    "    return inversed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4660b75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 60, 36), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window.test.take(1) # given 60 days of info, make prediction. Batch of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "84f2a73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 158ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "testData = window.test.take(1)\n",
    "testPredict = hypermodel.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "d60b5f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03850911],\n",
       "       [-0.08616414],\n",
       "       [-0.03508677],\n",
       "       [ 0.05452147],\n",
       "       [ 0.04328771],\n",
       "       [ 0.00158038],\n",
       "       [-0.07983816],\n",
       "       [-0.08319991],\n",
       "       [ 0.01772927],\n",
       "       [-0.08097013],\n",
       "       [ 0.04561995],\n",
       "       [-0.0857792 ],\n",
       "       [-0.13102858],\n",
       "       [ 0.02652507],\n",
       "       [-0.06717805],\n",
       "       [ 0.02680867],\n",
       "       [-0.06366231],\n",
       "       [-0.01168345],\n",
       "       [-0.02678484],\n",
       "       [ 0.02099827],\n",
       "       [-0.0386314 ],\n",
       "       [ 0.02127475],\n",
       "       [-0.07938855],\n",
       "       [-0.03992091],\n",
       "       [ 0.02334642],\n",
       "       [-0.05533672],\n",
       "       [-0.07522446],\n",
       "       [ 0.01150507],\n",
       "       [-0.06335182],\n",
       "       [ 0.05045534],\n",
       "       [ 0.01252339],\n",
       "       [-0.0454586 ]], dtype=float32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "ba52d6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04182623699307442,\n",
       " -0.04624743387103081,\n",
       " -0.04150872677564621,\n",
       " -0.03319532424211502,\n",
       " -0.034237537533044815,\n",
       " -0.03810693323612213,\n",
       " -0.04566054046154022,\n",
       " -0.04597242921590805,\n",
       " -0.03660871833562851,\n",
       " -0.04576556012034416,\n",
       " -0.03402116149663925,\n",
       " -0.04621171951293945,\n",
       " -0.05040973424911499,\n",
       " -0.03579268977046013,\n",
       " -0.044485997408628464,\n",
       " -0.03576637804508209,\n",
       " -0.044159822165966034,\n",
       " -0.039337486028671265,\n",
       " -0.04073851555585861,\n",
       " -0.03630543872714043,\n",
       " -0.04183758422732353,\n",
       " -0.036279790103435516,\n",
       " -0.045618828386068344,\n",
       " -0.04195721447467804,\n",
       " -0.03608758747577667,\n",
       " -0.04338741675019264,\n",
       " -0.04523250460624695,\n",
       " -0.03718617185950279,\n",
       " -0.044131018221378326,\n",
       " -0.03357255831360817,\n",
       " -0.0370916947722435,\n",
       " -0.04247097298502922]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Predicted Inflow ###\n",
    "\n",
    "# predictedInflow = testPredict.flatten() # Batch of 32 output\n",
    "predictedInflow = inverse_scaling(testPredict).flatten().tolist() # Batch of 32 output\n",
    "predictedInflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1c7ac9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:  [array([-0.01912978,  0.01490423,  0.01460248,  0.03595458,  0.02328497,\n",
      "       -0.03500219, -0.05108545, -0.00266521, -0.05396525, -0.10252491,\n",
      "        0.011954  , -0.12387791, -0.03209262, -0.00138498, -0.19309357,\n",
      "       -0.10602447,  0.0244406 , -0.02554115,  0.03212425, -0.1348074 ,\n",
      "       -0.20092668,  0.02369722, -0.0714507 , -0.05879815, -0.05191278,\n",
      "       -0.00870498, -0.09456588,  0.03157554,  0.01557928,  0.00769655,\n",
      "        0.01478095, -0.0250665 ], dtype=float32)]\n",
      "\n",
      "Actual inflow:  [0.47130533400923014, 0.5223563378676772, 0.5219037220813334, 0.553931875154376, 0.5349274575710297, 0.44749671407043934, 0.42337181977927685, 0.4960021789884195, 0.41905212216079235, 0.34621262922883034, 0.5179310017265379, 0.3141831308603287, 0.45186106488108635, 0.49792252416955307, 0.21035964787006378, 0.34096330031752586, 0.5366609022021294, 0.4616882763803005, 0.5481863822788, 0.29778891056776047, 0.19860998541116714, 0.5355458296835423, 0.3928239457309246, 0.41180277056992054, 0.42213083431124687, 0.48694252874702215, 0.3581511750817299, 0.5473633129149675, 0.5233689178712666, 0.5115448262076825, 0.5221714177168906, 0.4624002492055297]\n"
     ]
    }
   ],
   "source": [
    "### Actual Inflow ### \n",
    "\n",
    "windowTest = window.test.take(1); # Batch of 32\n",
    "target = [] # predicting 30 days ahead. Batch of 32.\n",
    "\n",
    "for inputs, labels in windowTest.as_numpy_iterator():\n",
    "  target = [np.asarray(labels).flatten()]\n",
    "  print('Before scaling: ', target)\n",
    "\n",
    "actualInflow = inverse_scaling(target).flatten().tolist()\n",
    "print('\\nActual inflow: ', actualInflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8412b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predicted and actual inflow values \n",
    "\n",
    "mean_absolute_error(actualInflow, predictedInflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af840c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
