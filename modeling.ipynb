{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9faa064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import datetime, os\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af03285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ea6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "\n",
    "DATA_PATH = 'Reservoir_Project/Data'\n",
    "HP_TUNING_PATH = 'Reservoir_Project/Hyperparameter_Tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1755769",
   "metadata": {},
   "outputs": [],
   "source": [
    "stationary_basin_inflow = pd.read_excel(f'{DATA_PATH}/Custom/stationary_basin_inflow.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f493ba",
   "metadata": {},
   "source": [
    "#### Scale data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61509a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFLOW</th>\n",
       "      <th>NFD_MEAN_FLOW</th>\n",
       "      <th>OXB_RIVER_STAGE</th>\n",
       "      <th>OXB_RIVER_DISCHARGE</th>\n",
       "      <th>CBR_RIVER_STAGE</th>\n",
       "      <th>CBR_RIVER_DISCHARGE</th>\n",
       "      <th>ADR_PRECIP_ACC</th>\n",
       "      <th>ADR_PRECIP_INCR</th>\n",
       "      <th>ADR_TEMP_AVG</th>\n",
       "      <th>ADR_TEMP_MAX</th>\n",
       "      <th>...</th>\n",
       "      <th>FRN_SNOW_DEPTH</th>\n",
       "      <th>FRN_SNOW_WATER_CONTENT</th>\n",
       "      <th>FRN_TEMP_AVG</th>\n",
       "      <th>FRN_TEMP_MAX</th>\n",
       "      <th>FRN_TEMP_MIN</th>\n",
       "      <th>PFH_PRECIP_ACC</th>\n",
       "      <th>PFH_PRECIP_INCR</th>\n",
       "      <th>PFH_TEMP_AVG</th>\n",
       "      <th>PFH_TEMP_MAX</th>\n",
       "      <th>PFH_TEMP_MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046224</td>\n",
       "      <td>0.051876</td>\n",
       "      <td>0.237069</td>\n",
       "      <td>0.063465</td>\n",
       "      <td>-0.401142</td>\n",
       "      <td>0.052915</td>\n",
       "      <td>-0.193228</td>\n",
       "      <td>0.317948</td>\n",
       "      <td>-0.136617</td>\n",
       "      <td>-0.445268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056802</td>\n",
       "      <td>-0.047357</td>\n",
       "      <td>-0.467484</td>\n",
       "      <td>-0.513988</td>\n",
       "      <td>-0.433957</td>\n",
       "      <td>-0.015267</td>\n",
       "      <td>0.226186</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.203656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046656</td>\n",
       "      <td>0.057364</td>\n",
       "      <td>0.244207</td>\n",
       "      <td>0.064644</td>\n",
       "      <td>-0.200977</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>-0.187313</td>\n",
       "      <td>0.353458</td>\n",
       "      <td>-0.248239</td>\n",
       "      <td>-0.443910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061424</td>\n",
       "      <td>-0.045370</td>\n",
       "      <td>-0.342164</td>\n",
       "      <td>-0.361327</td>\n",
       "      <td>-0.314145</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>0.300835</td>\n",
       "      <td>-0.168862</td>\n",
       "      <td>-0.689554</td>\n",
       "      <td>-0.172624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040509</td>\n",
       "      <td>0.060470</td>\n",
       "      <td>0.248504</td>\n",
       "      <td>0.064578</td>\n",
       "      <td>-0.182704</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>-0.184687</td>\n",
       "      <td>0.222780</td>\n",
       "      <td>-0.263400</td>\n",
       "      <td>-0.327549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065748</td>\n",
       "      <td>-0.043497</td>\n",
       "      <td>-0.183765</td>\n",
       "      <td>-0.177308</td>\n",
       "      <td>-0.160303</td>\n",
       "      <td>-0.004875</td>\n",
       "      <td>0.299022</td>\n",
       "      <td>-0.214953</td>\n",
       "      <td>-0.582226</td>\n",
       "      <td>-0.206942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036760</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>0.204183</td>\n",
       "      <td>0.046449</td>\n",
       "      <td>-0.152004</td>\n",
       "      <td>-0.003311</td>\n",
       "      <td>-0.195223</td>\n",
       "      <td>-0.324864</td>\n",
       "      <td>-0.287873</td>\n",
       "      <td>-0.270221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064547</td>\n",
       "      <td>-0.043564</td>\n",
       "      <td>-0.118437</td>\n",
       "      <td>-0.073134</td>\n",
       "      <td>-0.118773</td>\n",
       "      <td>-0.015040</td>\n",
       "      <td>-0.428473</td>\n",
       "      <td>-0.223444</td>\n",
       "      <td>-0.454890</td>\n",
       "      <td>-0.280173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002739</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0.154703</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>-0.165334</td>\n",
       "      <td>-0.016063</td>\n",
       "      <td>-0.205048</td>\n",
       "      <td>-0.399602</td>\n",
       "      <td>-0.225255</td>\n",
       "      <td>-0.180684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>-0.043065</td>\n",
       "      <td>-0.070014</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>-0.089780</td>\n",
       "      <td>-0.023395</td>\n",
       "      <td>-0.465585</td>\n",
       "      <td>-0.139686</td>\n",
       "      <td>-0.279272</td>\n",
       "      <td>-0.303446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INFLOW  NFD_MEAN_FLOW  OXB_RIVER_STAGE  OXB_RIVER_DISCHARGE  \\\n",
       "0  0.046224       0.051876         0.237069             0.063465   \n",
       "1  0.046656       0.057364         0.244207             0.064644   \n",
       "2  0.040509       0.060470         0.248504             0.064578   \n",
       "3  0.036760       0.061464         0.204183             0.046449   \n",
       "4 -0.002739       0.061806         0.154703             0.031689   \n",
       "\n",
       "   CBR_RIVER_STAGE  CBR_RIVER_DISCHARGE  ADR_PRECIP_ACC  ADR_PRECIP_INCR  \\\n",
       "0        -0.401142             0.052915       -0.193228         0.317948   \n",
       "1        -0.200977             0.026400       -0.187313         0.353458   \n",
       "2        -0.182704             0.000397       -0.184687         0.222780   \n",
       "3        -0.152004            -0.003311       -0.195223        -0.324864   \n",
       "4        -0.165334            -0.016063       -0.205048        -0.399602   \n",
       "\n",
       "   ADR_TEMP_AVG  ADR_TEMP_MAX  ...  FRN_SNOW_DEPTH  FRN_SNOW_WATER_CONTENT  \\\n",
       "0     -0.136617     -0.445268  ...        0.056802               -0.047357   \n",
       "1     -0.248239     -0.443910  ...        0.061424               -0.045370   \n",
       "2     -0.263400     -0.327549  ...        0.065748               -0.043497   \n",
       "3     -0.287873     -0.270221  ...        0.064547               -0.043564   \n",
       "4     -0.225255     -0.180684  ...        0.075019               -0.043065   \n",
       "\n",
       "   FRN_TEMP_AVG  FRN_TEMP_MAX  FRN_TEMP_MIN  PFH_PRECIP_ACC  PFH_PRECIP_INCR  \\\n",
       "0     -0.467484     -0.513988     -0.433957       -0.015267         0.226186   \n",
       "1     -0.342164     -0.361327     -0.314145       -0.010052         0.300835   \n",
       "2     -0.183765     -0.177308     -0.160303       -0.004875         0.299022   \n",
       "3     -0.118437     -0.073134     -0.118773       -0.015040        -0.428473   \n",
       "4     -0.070014      0.009671     -0.089780       -0.023395        -0.465585   \n",
       "\n",
       "   PFH_TEMP_AVG  PFH_TEMP_MAX  PFH_TEMP_MIN  \n",
       "0     -0.175380     -0.606621     -0.203656  \n",
       "1     -0.168862     -0.689554     -0.172624  \n",
       "2     -0.214953     -0.582226     -0.206942  \n",
       "3     -0.223444     -0.454890     -0.280173  \n",
       "4     -0.139686     -0.279272     -0.303446  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Normalizing data\n",
    "\n",
    "Maximum absolute scaling rescales each feature between -1 and 1 by dividing every observation \n",
    "by its maximum absolute value.\n",
    "\"\"\"\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "normalized_df = scaler.fit_transform(stationary_basin_inflow)\n",
    "\n",
    "normalized_basin_inflow = pd.DataFrame(normalized_df, columns=stationary_basin_inflow.columns) \n",
    "\n",
    "normalized_basin_inflow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec73825",
   "metadata": {},
   "source": [
    "#### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfc60b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70/20/10 split for training, validation, and test sets\n",
    "\n",
    "df_size = len(normalized_basin_inflow)\n",
    "\n",
    "basin_inflow_train = normalized_basin_inflow[0:int(df_size * 0.7)] # 70% \n",
    "\n",
    "basin_inflow_validation = normalized_basin_inflow[int(df_size * 0.7):int(df_size * 0.9)] # next 20%\n",
    "basin_inflow_validation.reset_index(drop=True, inplace=True)\n",
    "\n",
    "basin_inflow_test = normalized_basin_inflow[int(df_size * 0.9):] # last 10%\n",
    "basin_inflow_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60024804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INFLOW</th>\n",
       "      <th>NFD_MEAN_FLOW</th>\n",
       "      <th>OXB_RIVER_STAGE</th>\n",
       "      <th>OXB_RIVER_DISCHARGE</th>\n",
       "      <th>CBR_RIVER_STAGE</th>\n",
       "      <th>CBR_RIVER_DISCHARGE</th>\n",
       "      <th>ADR_PRECIP_ACC</th>\n",
       "      <th>ADR_PRECIP_INCR</th>\n",
       "      <th>ADR_TEMP_AVG</th>\n",
       "      <th>ADR_TEMP_MAX</th>\n",
       "      <th>...</th>\n",
       "      <th>FRN_SNOW_DEPTH</th>\n",
       "      <th>FRN_SNOW_WATER_CONTENT</th>\n",
       "      <th>FRN_TEMP_AVG</th>\n",
       "      <th>FRN_TEMP_MAX</th>\n",
       "      <th>FRN_TEMP_MIN</th>\n",
       "      <th>PFH_PRECIP_ACC</th>\n",
       "      <th>PFH_PRECIP_INCR</th>\n",
       "      <th>PFH_TEMP_AVG</th>\n",
       "      <th>PFH_TEMP_MAX</th>\n",
       "      <th>PFH_TEMP_MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046224</td>\n",
       "      <td>0.051876</td>\n",
       "      <td>0.237069</td>\n",
       "      <td>0.063465</td>\n",
       "      <td>-0.401142</td>\n",
       "      <td>0.052915</td>\n",
       "      <td>-0.193228</td>\n",
       "      <td>0.317948</td>\n",
       "      <td>-0.136617</td>\n",
       "      <td>-0.445268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056802</td>\n",
       "      <td>-0.047357</td>\n",
       "      <td>-0.467484</td>\n",
       "      <td>-0.513988</td>\n",
       "      <td>-0.433957</td>\n",
       "      <td>-0.015267</td>\n",
       "      <td>0.226186</td>\n",
       "      <td>-0.175380</td>\n",
       "      <td>-0.606621</td>\n",
       "      <td>-0.203656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046656</td>\n",
       "      <td>0.057364</td>\n",
       "      <td>0.244207</td>\n",
       "      <td>0.064644</td>\n",
       "      <td>-0.200977</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>-0.187313</td>\n",
       "      <td>0.353458</td>\n",
       "      <td>-0.248239</td>\n",
       "      <td>-0.443910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061424</td>\n",
       "      <td>-0.045370</td>\n",
       "      <td>-0.342164</td>\n",
       "      <td>-0.361327</td>\n",
       "      <td>-0.314145</td>\n",
       "      <td>-0.010052</td>\n",
       "      <td>0.300835</td>\n",
       "      <td>-0.168862</td>\n",
       "      <td>-0.689554</td>\n",
       "      <td>-0.172624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.040509</td>\n",
       "      <td>0.060470</td>\n",
       "      <td>0.248504</td>\n",
       "      <td>0.064578</td>\n",
       "      <td>-0.182704</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>-0.184687</td>\n",
       "      <td>0.222780</td>\n",
       "      <td>-0.263400</td>\n",
       "      <td>-0.327549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065748</td>\n",
       "      <td>-0.043497</td>\n",
       "      <td>-0.183765</td>\n",
       "      <td>-0.177308</td>\n",
       "      <td>-0.160303</td>\n",
       "      <td>-0.004875</td>\n",
       "      <td>0.299022</td>\n",
       "      <td>-0.214953</td>\n",
       "      <td>-0.582226</td>\n",
       "      <td>-0.206942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036760</td>\n",
       "      <td>0.061464</td>\n",
       "      <td>0.204183</td>\n",
       "      <td>0.046449</td>\n",
       "      <td>-0.152004</td>\n",
       "      <td>-0.003311</td>\n",
       "      <td>-0.195223</td>\n",
       "      <td>-0.324864</td>\n",
       "      <td>-0.287873</td>\n",
       "      <td>-0.270221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064547</td>\n",
       "      <td>-0.043564</td>\n",
       "      <td>-0.118437</td>\n",
       "      <td>-0.073134</td>\n",
       "      <td>-0.118773</td>\n",
       "      <td>-0.015040</td>\n",
       "      <td>-0.428473</td>\n",
       "      <td>-0.223444</td>\n",
       "      <td>-0.454890</td>\n",
       "      <td>-0.280173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002739</td>\n",
       "      <td>0.061806</td>\n",
       "      <td>0.154703</td>\n",
       "      <td>0.031689</td>\n",
       "      <td>-0.165334</td>\n",
       "      <td>-0.016063</td>\n",
       "      <td>-0.205048</td>\n",
       "      <td>-0.399602</td>\n",
       "      <td>-0.225255</td>\n",
       "      <td>-0.180684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075019</td>\n",
       "      <td>-0.043065</td>\n",
       "      <td>-0.070014</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>-0.089780</td>\n",
       "      <td>-0.023395</td>\n",
       "      <td>-0.465585</td>\n",
       "      <td>-0.139686</td>\n",
       "      <td>-0.279272</td>\n",
       "      <td>-0.303446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     INFLOW  NFD_MEAN_FLOW  OXB_RIVER_STAGE  OXB_RIVER_DISCHARGE  \\\n",
       "0  0.046224       0.051876         0.237069             0.063465   \n",
       "1  0.046656       0.057364         0.244207             0.064644   \n",
       "2  0.040509       0.060470         0.248504             0.064578   \n",
       "3  0.036760       0.061464         0.204183             0.046449   \n",
       "4 -0.002739       0.061806         0.154703             0.031689   \n",
       "\n",
       "   CBR_RIVER_STAGE  CBR_RIVER_DISCHARGE  ADR_PRECIP_ACC  ADR_PRECIP_INCR  \\\n",
       "0        -0.401142             0.052915       -0.193228         0.317948   \n",
       "1        -0.200977             0.026400       -0.187313         0.353458   \n",
       "2        -0.182704             0.000397       -0.184687         0.222780   \n",
       "3        -0.152004            -0.003311       -0.195223        -0.324864   \n",
       "4        -0.165334            -0.016063       -0.205048        -0.399602   \n",
       "\n",
       "   ADR_TEMP_AVG  ADR_TEMP_MAX  ...  FRN_SNOW_DEPTH  FRN_SNOW_WATER_CONTENT  \\\n",
       "0     -0.136617     -0.445268  ...        0.056802               -0.047357   \n",
       "1     -0.248239     -0.443910  ...        0.061424               -0.045370   \n",
       "2     -0.263400     -0.327549  ...        0.065748               -0.043497   \n",
       "3     -0.287873     -0.270221  ...        0.064547               -0.043564   \n",
       "4     -0.225255     -0.180684  ...        0.075019               -0.043065   \n",
       "\n",
       "   FRN_TEMP_AVG  FRN_TEMP_MAX  FRN_TEMP_MIN  PFH_PRECIP_ACC  PFH_PRECIP_INCR  \\\n",
       "0     -0.467484     -0.513988     -0.433957       -0.015267         0.226186   \n",
       "1     -0.342164     -0.361327     -0.314145       -0.010052         0.300835   \n",
       "2     -0.183765     -0.177308     -0.160303       -0.004875         0.299022   \n",
       "3     -0.118437     -0.073134     -0.118773       -0.015040        -0.428473   \n",
       "4     -0.070014      0.009671     -0.089780       -0.023395        -0.465585   \n",
       "\n",
       "   PFH_TEMP_AVG  PFH_TEMP_MAX  PFH_TEMP_MIN  \n",
       "0     -0.175380     -0.606621     -0.203656  \n",
       "1     -0.168862     -0.689554     -0.172624  \n",
       "2     -0.214953     -0.582226     -0.206942  \n",
       "3     -0.223444     -0.454890     -0.280173  \n",
       "4     -0.139686     -0.279272     -0.303446  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basin_inflow_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d978f",
   "metadata": {},
   "source": [
    "### Data windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d373e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow utility class for producing data windows from time series data\n",
    "\n",
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "    \n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "    \n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "aeb825cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.WindowGenerator at 0x2a5273c50>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Window\n",
    "- Given 60 days of history predict 30 days into the future. Why? A season is about 90 days in a CA WY\n",
    "- Window size: 90\n",
    "\"\"\"\n",
    "\n",
    "window = WindowGenerator(input_width=60, label_width=1, shift=30,\n",
    "                     train_df=basin_inflow_train, val_df=basin_inflow_validation, \n",
    "                     test_df=basin_inflow_test, label_columns=['INFLOW'])\n",
    "\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "379f5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a window of inputs and labels\n",
    "\n",
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # set shapes after slicing\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3e37dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset of sliding windows over a time series dataframe\n",
    "\n",
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=32,)\n",
    "\n",
    "  # (input_window, label_window) pairs \n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5f27daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "70d6de41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 60, 36), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each element is an (inputs, label) pair\n",
    "window.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "dd26e712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 60, 36)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# example batch\n",
    "for inputs, labels in window.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd065a",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "7fb21668",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "test_performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37286bc8",
   "metadata": {},
   "source": [
    "#### Create baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "29a12380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow baseline utility class for data windowing\n",
    "\n",
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs\n",
    "    result = inputs[:, :, self.label_index]\n",
    "    return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c392c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 488us/step - loss: 0.1517 - mean_absolute_error: 0.1517\n"
     ]
    }
   ],
   "source": [
    "baseline = Baseline(label_index=window.column_indices['INFLOW'])\n",
    "\n",
    "baseline.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance['Baseline'] = baseline.evaluate(window.val)\n",
    "test_performance['Baseline'] = baseline.evaluate(window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742bf48",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "fa2344c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping, tensorboard_callback])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372162e",
   "metadata": {},
   "source": [
    "LSTM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c3d2634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inputs shape (batch, time, features): (32, 60, 36) - 32 batch size, 60 time steps, 36 features\n",
    "\"\"\"\n",
    "\n",
    "lstm_v1 = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 36]),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d02e6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 9ms/step - loss: 0.0628 - val_loss: 0.1552\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0452 - val_loss: 0.1385\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0414 - val_loss: 0.1315\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0399 - val_loss: 0.1284\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0374 - val_loss: 0.1295\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0362 - val_loss: 0.1387\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v1 = compile_and_fit(lstm_v1, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1381954",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "400cf07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1387\n",
      "LSTM 1 Validation performance:  0.13874830305576324\n",
      "LSTM 1 Test performance:  0.14985796809196472\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM1'] = lstm_v1.evaluate(window.val)\n",
    "test_performance['LSTM1'] = lstm_v1.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 1 Validation performance: ', val_performance['LSTM1'])\n",
    "print('LSTM 1 Test performance: ', test_performance['LSTM1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a035828",
   "metadata": {},
   "source": [
    "LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6ce4faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v2 = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 36]),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e28ec0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 2s 17ms/step - loss: 0.0430 - val_loss: 0.1555\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0321 - val_loss: 0.1474\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0297 - val_loss: 0.1514\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0257 - val_loss: 0.1452\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0229 - val_loss: 0.1514\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 1s 14ms/step - loss: 0.0203 - val_loss: 0.1527\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v2 = compile_and_fit(lstm_v2, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec16a472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45646), started 0:23:25 ago. (Use '!kill 45646' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c40f9f7f74bb1ff\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c40f9f7f74bb1ff\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1c735a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 3ms/step - loss: 0.1527\n",
      "LSTM 2 Validation performance:  0.15269407629966736\n",
      "LSTM 2 Test performance:  0.09494537860155106\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM2'] = lstm_v2.evaluate(window.val)\n",
    "test_performance['LSTM2'] = lstm_v2.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 2 Validation performance: ', val_performance['LSTM2'])\n",
    "print('LSTM 2 Test performance: ', test_performance['LSTM2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a115cd1",
   "metadata": {},
   "source": [
    "LSTM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f2035563",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizedLSTM = partial(tf.keras.layers.LSTM,\n",
    "                           dropout=0.01,\n",
    "                           recurrent_dropout=0.01,\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "704200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v3 = tf.keras.models.Sequential([\n",
    "    RegularizedLSTM(32, return_sequences=True, input_shape=[None, 36]),\n",
    "    RegularizedLSTM(32),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8a5453af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 4s 34ms/step - loss: 3.0731 - val_loss: 1.5350\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.7713 - val_loss: 0.4343\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.1850 - val_loss: 0.1943\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0637 - val_loss: 0.1485\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0437 - val_loss: 0.1551\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0394 - val_loss: 0.1457\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0378 - val_loss: 0.1461\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0378 - val_loss: 0.1465\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v3 = compile_and_fit(lstm_v3, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dc31fe6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45646), started 2:07:43 ago. (Use '!kill 45646' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-219c1018de26f1f2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-219c1018de26f1f2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "be242d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 0.1465\n",
      "LSTM 3 Validation performance:  0.14650316536426544\n",
      "LSTM 3 Test performance:  0.07470374554395676\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM3'] = lstm_v3.evaluate(window.val)\n",
    "test_performance['LSTM3'] = lstm_v3.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 3 Validation performance: ', val_performance['LSTM3'])\n",
    "print('LSTM 3 Test performance: ', test_performance['LSTM3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2f773",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6b1cd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  lstm = keras.Sequential()\n",
    "\n",
    "  ### Tuning hyperparameters ### \n",
    "\n",
    "  # Number of lstm layer units\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "\n",
    "  # Dropout rate applied to input values\n",
    "  hp_dropout = hp.Choice(\"dropout\", [0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "  # Recurrent dropout rate applied to hidden cell states between time steps\n",
    "  hp_recurrent_dropout = hp.Choice(\"recurrent_dropout\", [0.2, 0.3, 0.4, 0.5])\n",
    "  \n",
    "  # L2 regularization \n",
    "  hp_l2_reg = hp.Choice(\"l2\", [0.001, 0.01, 0.02, 0.05])\n",
    "\n",
    "  # Optimizer learning rate\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "\n",
    "  ### Layers ### \n",
    "  \n",
    "  lstm.add(tf.keras.layers.LSTM(units=hp_units, dropout=hp_dropout, recurrent_dropout=hp_recurrent_dropout, \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2=hp_l2_reg),\n",
    "                  return_sequences=True, input_shape=[None, 36]))\n",
    "    \n",
    "  lstm.add(tf.keras.layers.LSTM(units=hp_units, dropout=hp_dropout, recurrent_dropout=hp_recurrent_dropout, \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2=hp_l2_reg)))\n",
    "    \n",
    "  lstm.add(keras.layers.Dense(1))    \n",
    "    \n",
    "  ### Compile ### \n",
    "           \n",
    "  lstm.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "               optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=hp_learning_rate),\n",
    "               metrics=['mean_absolute_error'])\n",
    "\n",
    "  return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "787226b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_mean_absolute_error',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory=HP_TUNING_PATH,\n",
    "                     project_name='reservoir_model_hp_tuning_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "b8071be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9a5ce375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 50s]\n",
      "val_mean_absolute_error: 0.11860812455415726\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.11121592670679092\n",
      "Total elapsed time: 00h 14m 04s\n"
     ]
    }
   ],
   "source": [
    "# args for search are those used for model fit\n",
    "tuner.search(window.train, epochs=MAX_EPOCHS, validation_data=window.val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7111e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete and below are the optimal values:\n",
      "\n",
      "- Units: 32\n",
      "- Dropout: 0.2\n",
      "- Recurrent dropout: 0.5\n",
      "- L2: 0.01\n",
      "- Learning rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete and below are the optimal values:\n",
    "\n",
    "- Units: {best_hps.get('units')}\n",
    "- Dropout: {best_hps.get('dropout')}\n",
    "- Recurrent dropout: {best_hps.get('recurrent_dropout')}\n",
    "- L2: {best_hps.get('l2')}\n",
    "- Learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8324d",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5cb0f6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 4s 34ms/step - loss: 0.7020 - mean_absolute_error: 0.0479 - val_loss: 0.4679 - val_mean_absolute_error: 0.1227\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.2459 - mean_absolute_error: 0.0383 - val_loss: 0.2452 - val_mean_absolute_error: 0.1337\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.1085 - mean_absolute_error: 0.0374 - val_loss: 0.1761 - val_mean_absolute_error: 0.1333\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0673 - mean_absolute_error: 0.0368 - val_loss: 0.1562 - val_mean_absolute_error: 0.1351\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0526 - mean_absolute_error: 0.0362 - val_loss: 0.1471 - val_mean_absolute_error: 0.1347\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0455 - mean_absolute_error: 0.0352 - val_loss: 0.1465 - val_mean_absolute_error: 0.1381\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0425 - mean_absolute_error: 0.0353 - val_loss: 0.1496 - val_mean_absolute_error: 0.1434\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 3s 35ms/step - loss: 0.0405 - mean_absolute_error: 0.0350 - val_loss: 0.1436 - val_mean_absolute_error: 0.1388\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0405 - mean_absolute_error: 0.0360 - val_loss: 0.1357 - val_mean_absolute_error: 0.1315\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 3s 34ms/step - loss: 0.0387 - mean_absolute_error: 0.0348 - val_loss: 0.1420 - val_mean_absolute_error: 0.1384\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# first find the optimal number of training epochs\n",
    "\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=2,\n",
    "                                                mode='min')\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(window.train, epochs=MAX_EPOCHS, validation_data=window.val, callbacks=[early_stopping])\n",
    "\n",
    "val_mae_per_epoch = history.history['val_mean_absolute_error']\n",
    "best_epoch = val_mae_per_epoch.index(min(val_mae_per_epoch)) + 1 # find epoch of lowest validation MAE \n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "75134ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 4s 35ms/step - loss: 0.7018 - mean_absolute_error: 0.0480 - val_loss: 0.4654 - val_mean_absolute_error: 0.1236\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=2,\n",
    "                                                mode='min')\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "history = hypermodel.fit(window.train, epochs=best_epoch, validation_data=window.val, \n",
    "                         callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ee1c25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4654 - mean_absolute_error: 0.1236\n",
      "Hypermodel Validation performance:  [0.4653622806072235, 0.1235504150390625]\n",
      "Hypermodel Test performance:  [0.38941654562950134, 0.04760463908314705]\n"
     ]
    }
   ],
   "source": [
    "val_performance['Hypermodel'] = hypermodel.evaluate(window.val)\n",
    "test_performance['Hypermodel'] = hypermodel.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('Hypermodel Validation performance: ', val_performance['Hypermodel'])\n",
    "print('Hypermodel Test performance: ', test_performance['Hypermodel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b60f1",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1fef4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse normalization\n",
    "\n",
    "def inverse_scaling(scaler, data):\n",
    "    fitted_scaler = scaler.fit(data)\n",
    "    inversed_data = fitted_scaler.inverse_transform(data)\n",
    "    return inversed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "463b6757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 60, 36), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window.test.take(1) # given 60 days of info, make prediction. Batch of 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "23dc3868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 158ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "testData = window.test.take(1)\n",
    "testPredict = hypermodel.predict(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "393d47aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03850911],\n",
       "       [-0.08616414],\n",
       "       [-0.03508677],\n",
       "       [ 0.05452147],\n",
       "       [ 0.04328771],\n",
       "       [ 0.00158038],\n",
       "       [-0.07983816],\n",
       "       [-0.08319991],\n",
       "       [ 0.01772927],\n",
       "       [-0.08097013],\n",
       "       [ 0.04561995],\n",
       "       [-0.0857792 ],\n",
       "       [-0.13102858],\n",
       "       [ 0.02652507],\n",
       "       [-0.06717805],\n",
       "       [ 0.02680867],\n",
       "       [-0.06366231],\n",
       "       [-0.01168345],\n",
       "       [-0.02678484],\n",
       "       [ 0.02099827],\n",
       "       [-0.0386314 ],\n",
       "       [ 0.02127475],\n",
       "       [-0.07938855],\n",
       "       [-0.03992091],\n",
       "       [ 0.02334642],\n",
       "       [-0.05533672],\n",
       "       [-0.07522446],\n",
       "       [ 0.01150507],\n",
       "       [-0.06335182],\n",
       "       [ 0.05045534],\n",
       "       [ 0.01252339],\n",
       "       [-0.0454586 ]], dtype=float32)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7e58fb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.04182623699307442,\n",
       " -0.04624743387103081,\n",
       " -0.04150872677564621,\n",
       " -0.03319532424211502,\n",
       " -0.034237537533044815,\n",
       " -0.03810693323612213,\n",
       " -0.04566054046154022,\n",
       " -0.04597242921590805,\n",
       " -0.03660871833562851,\n",
       " -0.04576556012034416,\n",
       " -0.03402116149663925,\n",
       " -0.04621171951293945,\n",
       " -0.05040973424911499,\n",
       " -0.03579268977046013,\n",
       " -0.044485997408628464,\n",
       " -0.03576637804508209,\n",
       " -0.044159822165966034,\n",
       " -0.039337486028671265,\n",
       " -0.04073851555585861,\n",
       " -0.03630543872714043,\n",
       " -0.04183758422732353,\n",
       " -0.036279790103435516,\n",
       " -0.045618828386068344,\n",
       " -0.04195721447467804,\n",
       " -0.03608758747577667,\n",
       " -0.04338741675019264,\n",
       " -0.04523250460624695,\n",
       " -0.03718617185950279,\n",
       " -0.044131018221378326,\n",
       " -0.03357255831360817,\n",
       " -0.0370916947722435,\n",
       " -0.04247097298502922]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Predicted Inflow ###\n",
    "\n",
    "# predictedInflow = testPredict.flatten() # Batch of 32 output\n",
    "predictedInflow = inverse_scaling(scaler, testPredict).flatten().tolist() # Batch of 32 output\n",
    "predictedInflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f5c0c755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before scaling:  [array([-0.01912978,  0.01490423,  0.01460248,  0.03595458,  0.02328497,\n",
      "       -0.03500219, -0.05108545, -0.00266521, -0.05396525, -0.10252491,\n",
      "        0.011954  , -0.12387791, -0.03209262, -0.00138498, -0.19309357,\n",
      "       -0.10602447,  0.0244406 , -0.02554115,  0.03212425, -0.1348074 ,\n",
      "       -0.20092668,  0.02369722, -0.0714507 , -0.05879815, -0.05191278,\n",
      "       -0.00870498, -0.09456588,  0.03157554,  0.01557928,  0.00769655,\n",
      "        0.01478095, -0.0250665 ], dtype=float32)]\n",
      "\n",
      "Actual inflow:  [0.47130533400923014, 0.5223563378676772, 0.5219037220813334, 0.553931875154376, 0.5349274575710297, 0.44749671407043934, 0.42337181977927685, 0.4960021789884195, 0.41905212216079235, 0.34621262922883034, 0.5179310017265379, 0.3141831308603287, 0.45186106488108635, 0.49792252416955307, 0.21035964787006378, 0.34096330031752586, 0.5366609022021294, 0.4616882763803005, 0.5481863822788, 0.29778891056776047, 0.19860998541116714, 0.5355458296835423, 0.3928239457309246, 0.41180277056992054, 0.42213083431124687, 0.48694252874702215, 0.3581511750817299, 0.5473633129149675, 0.5233689178712666, 0.5115448262076825, 0.5221714177168906, 0.4624002492055297]\n"
     ]
    }
   ],
   "source": [
    "### Actual Inflow ### \n",
    "\n",
    "windowTest = window.test.take(1); # Batch of 32\n",
    "target = [] # predicting 30 days ahead. Batch of 32.\n",
    "\n",
    "for inputs, labels in windowTest.as_numpy_iterator():\n",
    "  target = [np.asarray(labels).flatten()]\n",
    "  print('Before scaling: ', target)\n",
    "\n",
    "actualInflow = inverse_scaling(scaler, target).flatten().tolist()\n",
    "print('\\nActual inflow: ', actualInflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f46aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare predicted and actual inflow values \n",
    "\n",
    "mean_absolute_error(actualInflow, predictedInflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758fd5c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
