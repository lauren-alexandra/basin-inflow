{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9faa064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import datetime, os\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow import keras\n",
    "import keras_tuner as kt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6deebeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93ea6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "\n",
    "DATA_PATH = 'Reservoir_Project/Data'\n",
    "HP_TUNING_PATH = 'Reservoir_Project/Hyperparameter_Tuning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd49ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "basin_inflow_train = pd.read_excel(f'{DATA_PATH}/Custom/basin_inflow_train.xlsx', index_col=0)\n",
    "basin_inflow_validation = pd.read_excel(f'{DATA_PATH}/Custom/basin_inflow_validation.xlsx', index_col=0)\n",
    "basin_inflow_test = pd.read_excel(f'{DATA_PATH}/Custom/basin_inflow_test.xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d978f",
   "metadata": {},
   "source": [
    "### Data windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d373e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow utility class for producing data windows from time series data\n",
    "\n",
    "class WindowGenerator():\n",
    "  def __init__(self, input_width, label_width, shift,\n",
    "               train_df, val_df, test_df,\n",
    "               label_columns=None):\n",
    "    # Store the raw data.\n",
    "    self.train_df = train_df\n",
    "    self.val_df = val_df\n",
    "    self.test_df = test_df\n",
    "    \n",
    "    self.column_indices = {name: i for i, name in\n",
    "                           enumerate(train_df.columns)}\n",
    "    \n",
    "    # Work out the label column indices.\n",
    "    self.label_columns = label_columns\n",
    "    if label_columns is not None:\n",
    "      self.label_columns_indices = {name: i for i, name in\n",
    "                                    enumerate(label_columns)}\n",
    "\n",
    "    # Work out the window parameters.\n",
    "    self.input_width = input_width\n",
    "    self.label_width = label_width\n",
    "    self.shift = shift\n",
    "\n",
    "    self.total_window_size = input_width + shift\n",
    "\n",
    "    self.input_slice = slice(0, input_width)\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "\n",
    "    self.label_start = self.total_window_size - self.label_width\n",
    "    self.labels_slice = slice(self.label_start, None)\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aeb825cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.WindowGenerator at 0x2c9d43c10>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Window\n",
    "- Given 60 days of history predict 30 days into the future. Why? A season is about 90 days in a CA WY\n",
    "- Window size: 90\n",
    "\"\"\"\n",
    "\n",
    "window = WindowGenerator(input_width=60, label_width=1, shift=30,\n",
    "                     train_df=basin_inflow_train, val_df=basin_inflow_validation, \n",
    "                     test_df=basin_inflow_test, label_columns=['INFLOW'])\n",
    "\n",
    "window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "379f5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a window of inputs and labels\n",
    "\n",
    "def split_window(self, features):\n",
    "  inputs = features[:, self.input_slice, :]\n",
    "  labels = features[:, self.labels_slice, :]\n",
    "  if self.label_columns is not None:\n",
    "    labels = tf.stack(\n",
    "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "        axis=-1)\n",
    "\n",
    "  # set shapes after slicing\n",
    "  inputs.set_shape([None, self.input_width, None])\n",
    "  labels.set_shape([None, self.label_width, None])\n",
    "\n",
    "  return inputs, labels\n",
    "\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3e37dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset of sliding windows over a time series dataframe\n",
    "\n",
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=True,\n",
    "      batch_size=32,)\n",
    "\n",
    "  # (input_window, label_window) pairs \n",
    "  ds = ds.map(self.split_window)\n",
    "\n",
    "  return ds\n",
    "\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f27daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "70d6de41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 60, 39), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each element is an (inputs, label) pair\n",
    "window.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd26e712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape (batch, time, features): (32, 60, 39)\n",
      "Labels shape (batch, time, features): (32, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# example batch\n",
    "for inputs, labels in window.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd065a",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7fb21668",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "test_performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37286bc8",
   "metadata": {},
   "source": [
    "#### Create baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "29a12380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow baseline utility class for data windowing\n",
    "\n",
    "class Baseline(tf.keras.Model):\n",
    "  def __init__(self, label_index=None):\n",
    "    super().__init__()\n",
    "    self.label_index = label_index\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if self.label_index is None:\n",
    "      return inputs\n",
    "    result = inputs[:, :, self.label_index]\n",
    "    return result[:, :, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c392c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 481us/step - loss: 0.0870 - mean_absolute_error: 0.0870\n"
     ]
    }
   ],
   "source": [
    "baseline = Baseline(label_index=window.column_indices['INFLOW'])\n",
    "\n",
    "baseline.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                 metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "val_performance['Baseline'] = baseline.evaluate(window.val)\n",
    "test_performance['Baseline'] = baseline.evaluate(window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742bf48",
   "metadata": {},
   "source": [
    "#### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa2344c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "  model.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "                optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping, tensorboard_callback])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372162e",
   "metadata": {},
   "source": [
    "LSTM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3d2634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inputs shape (batch, time, features): (32, 60, 39) - 32 batch size, 60 time steps, 39 features\n",
    "\"\"\"\n",
    "\n",
    "lstm_v1 = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 39]),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d02e6ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "112/112 [==============================] - 2s 9ms/step - loss: 0.0771 - val_loss: 0.0756\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0613 - val_loss: 0.0769\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0560 - val_loss: 0.0822\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v1 = compile_and_fit(lstm_v1, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1381954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "400cf07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0822\n",
      "LSTM 1 Validation performance:  0.08217944949865341\n",
      "LSTM 1 Test performance:  0.038288358598947525\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM1'] = lstm_v1.evaluate(window.val)\n",
    "test_performance['LSTM1'] = lstm_v1.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 1 Validation performance: ', val_performance['LSTM1'])\n",
    "print('LSTM 1 Test performance: ', test_performance['LSTM1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a035828",
   "metadata": {},
   "source": [
    "LSTM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ce4faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v2 = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True, input_shape=[None, 39]),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e28ec0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "112/112 [==============================] - 4s 17ms/step - loss: 0.0618 - val_loss: 0.0704\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.0418 - val_loss: 0.0638\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.0367 - val_loss: 0.0646\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 2s 14ms/step - loss: 0.0320 - val_loss: 0.0706\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v2 = compile_and_fit(lstm_v2, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c735a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0706\n",
      "LSTM 2 Validation performance:  0.0705932155251503\n",
      "LSTM 2 Test performance:  0.05622085556387901\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM2'] = lstm_v2.evaluate(window.val)\n",
    "test_performance['LSTM2'] = lstm_v2.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 2 Validation performance: ', val_performance['LSTM2'])\n",
    "print('LSTM 2 Test performance: ', test_performance['LSTM2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a115cd1",
   "metadata": {},
   "source": [
    "LSTM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2035563",
   "metadata": {},
   "outputs": [],
   "source": [
    "RegularizedLSTM = partial(tf.keras.layers.LSTM,\n",
    "                           dropout=0.01,\n",
    "                           recurrent_dropout=0.01,\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "704200c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_v3 = tf.keras.models.Sequential([\n",
    "    RegularizedLSTM(32, return_sequences=True, input_shape=[None, 39]),\n",
    "    RegularizedLSTM(32),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a5453af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "112/112 [==============================] - 7s 34ms/step - loss: 2.6534 - val_loss: 0.8579\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 4s 35ms/step - loss: 0.3875 - val_loss: 0.1369\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 4s 35ms/step - loss: 0.0946 - val_loss: 0.0694\n",
      "Epoch 4/10\n",
      "112/112 [==============================] - 4s 36ms/step - loss: 0.0680 - val_loss: 0.0657\n",
      "Epoch 5/10\n",
      "112/112 [==============================] - 4s 34ms/step - loss: 0.0655 - val_loss: 0.0685\n",
      "Epoch 6/10\n",
      "112/112 [==============================] - 4s 34ms/step - loss: 0.0653 - val_loss: 0.0688\n"
     ]
    }
   ],
   "source": [
    "history_lstm_v3 = compile_and_fit(lstm_v3, window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be242d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0688\n",
      "LSTM 3 Validation performance:  0.0688057541847229\n",
      "LSTM 3 Test performance:  0.040907714515924454\n"
     ]
    }
   ],
   "source": [
    "val_performance['LSTM3'] = lstm_v3.evaluate(window.val)\n",
    "test_performance['LSTM3'] = lstm_v3.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('LSTM 3 Validation performance: ', val_performance['LSTM3'])\n",
    "print('LSTM 3 Test performance: ', test_performance['LSTM3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2f773",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b1cd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  lstm = keras.Sequential()\n",
    "\n",
    "  ### Tuning hyperparameters ### \n",
    "\n",
    "  # Number of lstm layer units\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "\n",
    "  # Dropout rate applied to input values\n",
    "  hp_dropout = hp.Choice(\"dropout\", [0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "  # Recurrent dropout rate applied to hidden cell states between time steps\n",
    "  hp_recurrent_dropout = hp.Choice(\"recurrent_dropout\", [0.2, 0.3, 0.4, 0.5])\n",
    "  \n",
    "  # L2 regularization \n",
    "  hp_l2_reg = hp.Choice(\"l2\", [0.001, 0.01, 0.02, 0.05])\n",
    "\n",
    "  # Optimizer learning rate\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[0.01, 0.001, 0.0001])\n",
    "\n",
    "  ### Layers ### \n",
    "  \n",
    "  lstm.add(tf.keras.layers.LSTM(units=hp_units, dropout=hp_dropout, recurrent_dropout=hp_recurrent_dropout, \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2=hp_l2_reg),\n",
    "                  return_sequences=True, input_shape=[None, 39]))\n",
    "    \n",
    "  lstm.add(tf.keras.layers.LSTM(units=hp_units, dropout=hp_dropout, recurrent_dropout=hp_recurrent_dropout, \n",
    "                  kernel_regularizer=tf.keras.regularizers.l2(l2=hp_l2_reg)))\n",
    "    \n",
    "  lstm.add(keras.layers.Dense(1))    \n",
    "    \n",
    "  ### Compile ### \n",
    "           \n",
    "  lstm.compile(loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "               optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=hp_learning_rate),\n",
    "               metrics=['mean_absolute_error'])\n",
    "\n",
    "  return lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67fa2ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from /Reservoir_Project/Hyperparameter_Tuning/reservoir_model_hp_tuning_v3/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_mean_absolute_error',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory=HP_TUNING_PATH,\n",
    "                     project_name='reservoir_model_hp_tuning_v3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8071be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 10\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a5ce375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args for search are those used for model fit\n",
    "tuner.search(window.train, epochs=MAX_EPOCHS, validation_data=window.val, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7111e63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete and below are the optimal values:\n",
      "\n",
      "- Units: 32\n",
      "- Dropout: 0.4\n",
      "- Recurrent dropout: 0.3\n",
      "- L2: 0.02\n",
      "- Learning rate: 0.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete and below are the optimal values:\n",
    "\n",
    "- Units: {best_hps.get('units')}\n",
    "- Dropout: {best_hps.get('dropout')}\n",
    "- Recurrent dropout: {best_hps.get('recurrent_dropout')}\n",
    "- L2: {best_hps.get('l2')}\n",
    "- Learning rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8324d",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5cb0f6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "112/112 [==============================] - 6s 34ms/step - loss: 0.2247 - mean_absolute_error: 0.0740 - val_loss: 0.0616 - val_mean_absolute_error: 0.0532\n",
      "Epoch 2/10\n",
      "112/112 [==============================] - 4s 34ms/step - loss: 0.0746 - mean_absolute_error: 0.0680 - val_loss: 0.0705 - val_mean_absolute_error: 0.0636\n",
      "Epoch 3/10\n",
      "112/112 [==============================] - 4s 34ms/step - loss: 0.0720 - mean_absolute_error: 0.0660 - val_loss: 0.0630 - val_mean_absolute_error: 0.0576\n",
      "Best epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# first find the optimal number of training epochs\n",
    "\n",
    "MAX_EPOCHS = 10\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=2,\n",
    "                                                mode='min')\n",
    "\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(window.train, epochs=MAX_EPOCHS, validation_data=window.val, callbacks=[early_stopping])\n",
    "\n",
    "val_mae_per_epoch = history.history['val_mean_absolute_error']\n",
    "best_epoch = val_mae_per_epoch.index(min(val_mae_per_epoch)) + 1 # find epoch of lowest validation MAE \n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75134ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 6s 35ms/step - loss: 0.2198 - mean_absolute_error: 0.0729 - val_loss: 0.0692 - val_mean_absolute_error: 0.0647\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=2,\n",
    "                                                mode='min')\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "history = hypermodel.fit(window.train, epochs=best_epoch, validation_data=window.val, \n",
    "                         callbacks=[early_stopping, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee1c25f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0692 - mean_absolute_error: 0.0647\n",
      "Hypermodel Validation performance:  [0.0692351832985878, 0.06467919051647186]\n",
      "Hypermodel Test performance:  [0.040652964264154434, 0.036096975207328796]\n"
     ]
    }
   ],
   "source": [
    "val_performance['Hypermodel'] = hypermodel.evaluate(window.val)\n",
    "test_performance['Hypermodel'] = hypermodel.evaluate(window.test, verbose=0)\n",
    "\n",
    "print('Hypermodel Validation performance: ', val_performance['Hypermodel'])\n",
    "print('Hypermodel Test performance: ', test_performance['Hypermodel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b60f1",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23dc3868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 60, 39), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowTestBatch = window.test.take(1) # given 60 days of info, make prediction: batch of 32\n",
    "windowTestBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "393d47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 237ms/step\n"
     ]
    }
   ],
   "source": [
    "### Predicted Inflow ### \n",
    "\n",
    "predictedInflow = hypermodel.predict(windowTestBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d4e2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Actual Inflow ### \n",
    "\n",
    "actualInflow = [] # predicting 30 days ahead: batch of 32\n",
    "\n",
    "for inputs, labels in windowTestBatch.as_numpy_iterator():\n",
    "  actualInflow = np.asarray(labels).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "758fd5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.036947846"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare predicted and actual inflow: MAE \n",
    "\n",
    "mean_absolute_error(actualInflow, predictedInflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a2dbcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain absolute maximum inflow value for inverse scaling\n",
    "\n",
    "basin_inflow = pd.read_excel(f'{DATA_PATH}/Custom/basin_inflow_no_dates.xlsx', index_col=0)\n",
    "basin_inflow_test = basin_inflow[int(df_size * 0.9):] # last 10%\n",
    "basin_inflow_test.reset_index(drop=True, inplace=True)\n",
    "INFLOW_ABS_MAX = basin_inflow_test['INFLOW'].abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "055cf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse scaling for cfs prediction (predicting next 30 days)\n",
    "\n",
    "def inverse_scaling(predictions):\n",
    "    next_30_days = predictions[0:30]\n",
    "    \n",
    "    print('Next 30 Days of Inflow\\n')\n",
    "    for idx, target in enumerate(next_30_days):\n",
    "        day = idx + 1\n",
    "        print(\"{}. {:.3f} cfs\".format(day, target[0] * INFLOW_ABS_MAX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "84c8e0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next 30 Days of Inflow\n",
      "\n",
      "1. 4202.729 cfs\n",
      "2. 5746.163 cfs\n",
      "3. 3263.437 cfs\n",
      "4. 3719.474 cfs\n",
      "5. 3237.862 cfs\n",
      "6. 4481.116 cfs\n",
      "7. 3136.901 cfs\n",
      "8. 3682.255 cfs\n",
      "9. 5172.745 cfs\n",
      "10. 3076.100 cfs\n",
      "11. 3712.135 cfs\n",
      "12. 3342.944 cfs\n",
      "13. 3180.339 cfs\n",
      "14. 4432.857 cfs\n",
      "15. 5544.335 cfs\n",
      "16. 3896.251 cfs\n",
      "17. 5737.286 cfs\n",
      "18. 3015.898 cfs\n",
      "19. 3763.401 cfs\n",
      "20. 4742.780 cfs\n",
      "21. 5941.011 cfs\n",
      "22. 5164.979 cfs\n",
      "23. 3095.047 cfs\n",
      "24. 2320.619 cfs\n",
      "25. 5168.629 cfs\n",
      "26. 5729.252 cfs\n",
      "27. 5968.246 cfs\n",
      "28. 3952.693 cfs\n",
      "29. 3548.037 cfs\n",
      "30. 6362.657 cfs\n"
     ]
    }
   ],
   "source": [
    "inverse_scaling(predictedInflow)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
